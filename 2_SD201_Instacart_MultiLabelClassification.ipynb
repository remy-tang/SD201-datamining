{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"SD201-Instacart-MultiLabelClassification.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"HNu4gWEe6jFc"},"source":["# SD201 Project "]},{"cell_type":"markdown","metadata":{"id":"H58LEM-p6jFi"},"source":["## Dataset (from a Kaggle competition) : Instacart Market Basket Analysis\n","\n","Link : https://www.kaggle.com/c/instacart-market-basket-analysis/data\n","\n","Blog post about the competition : https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2\n","\n","Key points from the dataset:\n","\n","- 3M grocery store orders\n","- 200,000+ Instacart users\n","- 4 to 100 orders for each user, timestamped\n","\n","“The Instacart Online Grocery Shopping Dataset 2017”, Accessed from https://www.instacart.com/datasets/grocery-shopping-2017 on 10/12/2021\""]},{"cell_type":"markdown","metadata":{"id":"M8dXK7_G6jFl"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"s8-Mt_p56jFn"},"source":["In this project, we seek to predict the next basket items for a client given a history of past orders. This is a multi-label classification problem.\n","\n","Auxiliary questions :\n","\n","- relation between item categories and associations (Apriori algorithm) ?\n","- clustering of aisles/departments ?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d39Vhguc6umn","executionInfo":{"status":"ok","timestamp":1638875841534,"user_tz":-60,"elapsed":219,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"efcb40aa-1f53-4417-8d22-1e35b55cd23a"},"source":["# Mount the private Google Drive folder to access the .csv files\n","from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"xuEqPgz46jFt","executionInfo":{"status":"ok","timestamp":1638875843681,"user_tz":-60,"elapsed":1808,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["'''Python librairies''' \n","\n","# Utility librairies\n","import pandas as pd\n","import scipy.stats as s\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Preprocessing and pipeline librairies\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Wrapper to convert regular classifiers to multi-label classifiers\n","from sklearn.multioutput import MultiOutputClassifier\n","\n","# Classifiers that support multi-label output\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","import lightgbm as lgb\n","import xgboost as xgb\n","\n","# Kernel approximation for SVM methods (unused)\n","from sklearn.kernel_approximation import Nystroem\n","\n","# Metrics\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.metrics import hamming_loss, jaccard_score\n","\n","# Pretty charts\n","import seaborn as sns\n","sns.set_theme(style=\"ticks\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"V4eTpcxL6jFw","executionInfo":{"status":"ok","timestamp":1638875857433,"user_tz":-60,"elapsed":13758,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["op_prior = pd.read_csv('./My Drive/Etudes/Télécom Paris/Cours 2A/SD201/project/instacart/order_products__prior.csv')\n","op_train = pd.read_csv('./My Drive/Etudes/Télécom Paris/Cours 2A/SD201/project/instacart/order_products__train.csv')\n","orders = pd.read_csv('./My Drive/Etudes/Télécom Paris/Cours 2A/SD201/project/instacart/orders.csv')\n","products = pd.read_csv('./My Drive/Etudes/Télécom Paris/Cours 2A/SD201/project/instacart/products.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"un2cnv2u6jGG"},"source":["## Data cleaning"]},{"cell_type":"markdown","metadata":{"id":"ujUGWInbccn5"},"source":["The products DataFrame has some missing items (the indexes skip at some points and become slightly offset). This may lead to issues later on when using loc (from pandas) to locate data. We choose to set the index as the product_id."]},{"cell_type":"code","metadata":{"id":"uvnGnlqIcbUu","executionInfo":{"status":"ok","timestamp":1638875857436,"user_tz":-60,"elapsed":14,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["products.set_index('product_id', inplace=True)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lOWv5T9O6jGG"},"source":["We can check that the only problem we have with missing values are in the `orders` file, in which a certain number of `days_since_prior_order` entries are missing."]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"oYMgb1wi6jGH","executionInfo":{"status":"ok","timestamp":1638875857771,"user_tz":-60,"elapsed":346,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"08822f8c-62ee-46e4-a2b7-581e74e844eb"},"source":["orders.isnull().sum()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["order_id                       0\n","user_id                        0\n","eval_set                       0\n","order_number                   0\n","order_dow                      0\n","order_hour_of_day              0\n","days_since_prior_order    206209\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgZJxE436jGI","executionInfo":{"status":"ok","timestamp":1638875857772,"user_tz":-60,"elapsed":16,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"f1ce7e3a-fef2-4780-d352-4afd008c2468"},"source":["np.sort(orders.days_since_prior_order.unique())"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n","       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n","       26., 27., 28., 29., 30., nan])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"swSysluH6jGI"},"source":["We need to figure out what to do with `nan` entries in days_since_prior order."]},{"cell_type":"markdown","metadata":{"id":"rpExjSQS6jGJ"},"source":["What exactly are those entries? Counting the number of unique clients, we get that there are exactly as many null entries as there are clients."]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"mXdAx8pW6jGJ","executionInfo":{"status":"ok","timestamp":1638875857774,"user_tz":-60,"elapsed":14,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"b04df9b8-73f2-4cc7-b3cb-92be900a8eb3"},"source":["len(orders.user_id.unique())"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["206209"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"nuKnn5sw6jGJ"},"source":["Intuitively, we can guess that those null entries correspond to the first order for each of those clients. We can check this by counting the number of null entries for each client."]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"oOEXuZMg6jGJ","executionInfo":{"status":"ok","timestamp":1638875857776,"user_tz":-60,"elapsed":12,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"7bf4c976-da3e-479d-8371-2b7f4928713c"},"source":["orders.days_since_prior_order.isnull().groupby(orders['user_id']).sum().unique()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"dVgEoRmh6jGK"},"source":["We indeed get exactly one `nan` entry for each client, which confirms our assumption that those entries correpond to the first order for each client."]},{"cell_type":"markdown","metadata":{"id":"t533Rrgj6jGK"},"source":["What could be a good strategy for dealing with those entries?\n","\n","We could try either to drop them entirely from our dataset, or to backfill them with some value (be it the average elasped time for all orders, or the average elapsed time between two orders for the given client).\n","\n","Since most clients only have 4 orders, dropping the first order would mean dropping 25% of the data for this client. For this reason, we choose not to drop any row.\n","\n","We can compare both methods using pipelines."]},{"cell_type":"markdown","metadata":{"id":"M-UcGR5X6jGL"},"source":["### Formatting the data "]},{"cell_type":"markdown","metadata":{"id":"EgD37g8C6jGL"},"source":["We cannot exploit our relational data directly: we need to perform merges using the keys in the data, and then perform an aggregation over the ordered products to get arrays for each cart.\n","\n","Moreover, we do not need to perform a merge over the `products` DataFrame because the data there is redundant and already fully determined by the `product_id`. Therefore performing a merge there would induce data-leakage when training our model."]},{"cell_type":"code","metadata":{"id":"W0udu5p3SHDs","executionInfo":{"status":"ok","timestamp":1638875859246,"user_tz":-60,"elapsed":1480,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["threshold = 10e-4\n","order_count = len(op_prior)\n","\n","# Create the DataFrame of ordered products with their frequencies\n","item_freq = op_prior.product_id.value_counts(ascending=False)\n","item_freq = pd.DataFrame(item_freq.reset_index())\n","item_freq.rename(columns={'product_id':'n_occ', 'index':'product_id'}, inplace= True)\n","item_freq['frequency'] = item_freq['n_occ']/order_count"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsrWrRQPbDjm","executionInfo":{"status":"ok","timestamp":1638875859248,"user_tz":-60,"elapsed":13,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"5978459f-c680-4b9d-c780-c8ac177a6f2e"},"source":["# Compare the number of products before and after the drop\n","bf_size = len(item_freq)\n","item_freq = item_freq[item_freq.frequency>threshold]\n","af_size = len(item_freq)\n","print('Number of products before :', bf_size, 'after:', af_size)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of products before : 49677 after: 101\n"]}]},{"cell_type":"code","metadata":{"id":"-K6px5nuSKer","executionInfo":{"status":"ok","timestamp":1638875864988,"user_tz":-60,"elapsed":5750,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# # Keep first item in cart\n","# first_item_prior = op_prior[op_prior.add_to_cart_order == 1]\n","\n","# Drop all rows with unfrequently bought products\n","op_prior = op_prior[op_prior.product_id.isin(item_freq.product_id)]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQ17OsUM6jGL","executionInfo":{"status":"ok","timestamp":1638875864990,"user_tz":-60,"elapsed":9,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["def arrange_data(op_data):\n","    '''\n","    Format the data so that to each order corresponds an array of product_id (the cart),\n","    and an array indicating whether an item was reordered or not.\n","    op_data can be either op_train or op_prior.\n","    '''\n","    data = orders.merge(op_data[['order_id', 'product_id']], on='order_id')\n","    \n","    # Aggregate the carts into arrays\n","    groupby_cols = ['order_id',\n","                'user_id',\n","                'eval_set',\n","                'order_number',\n","                'order_dow',\n","                'order_hour_of_day',\n","                'days_since_prior_order']\n","    \n","    data = data.groupby(groupby_cols).aggregate(list)\n","    \n","    # Rename the product_id column to 'cart'\n","    data.rename(columns = {'product_id':'cart'}, inplace = True)\n","    \n","    # Reset the index that was changed by the aggregation\n","    data = data.reset_index()\n","    \n","    return data"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KfnmOKD6jGL","executionInfo":{"status":"ok","timestamp":1638875933859,"user_tz":-60,"elapsed":68876,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# Create the DataFrame with aggregated carts for each order\n","train_data = arrange_data(op_prior)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"0L1lYwdFBJ77","executionInfo":{"status":"ok","timestamp":1638875933863,"user_tz":-60,"elapsed":15,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# Free the RAM for Google Colab\n","op_prior = None"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oh9Ft8gH6jGL","executionInfo":{"status":"ok","timestamp":1638873483238,"user_tz":-60,"elapsed":16,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# # Change the data types for all columns to optimize memory use.\n","\n","# # We compare the memory saved by changing the data types.\n","# before_m = train_data.memory_usage().sum()\n","\n","# # We must signal to Python that these columns represent categorical data \n","# # so that the models work correctly.\n","# train_data['order_id'] = train_data['order_id'].astype('category')\n","# train_data['user_id'] = train_data['user_id'].astype('category')\n","# train_data['eval_set'] = train_data['eval_set'].astype('category')\n","# train_data['order_number'] = train_data['order_number'].astype('category')\n","\n","# train_data['order_dow'] = train_data['order_dow'].astype('uint8')\n","# train_data['order_hour_of_day'] = train_data['order_hour_of_day'].astype('uint8')\n","# train_data['days_since_prior_order'] = train_data['days_since_prior_order'].astype('float16')\n","# after_m = train_data.memory_usage().sum()\n","\n","# # How much memory have we saved ?\n","# (before_m-after_m)/before_m"],"execution_count":128,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DFsS0u_e6jGM"},"source":["## Feature engineering (unused)"]},{"cell_type":"markdown","metadata":{"id":"euq0lSz9X9K9"},"source":["Section is discarded for this project"]},{"cell_type":"markdown","metadata":{"id":"eaGynVqD6jGN"},"source":["#### Creating new features "]},{"cell_type":"code","metadata":{"id":"x0Ec-8hc6jGN","executionInfo":{"status":"ok","timestamp":1638867174671,"user_tz":-60,"elapsed":220,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# # Number of items in the cart\n","# train_data['n_products'] = train_data.cart.apply(lambda x: len(x))\n","# train_data['n_products'] = train_data['n_products'].astype('uint8')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSY4QkXC6jGN","executionInfo":{"status":"ok","timestamp":1638867174672,"user_tz":-60,"elapsed":12,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# # Number of reordered items in the cart\n","# train_data['n_reord'] = train_data.reordered.apply(lambda x: np.count_nonzero(x))\n","# train_data['n_reord'] = train_data['n_reord'].astype('uint8')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2lyC3cQ6jGN","executionInfo":{"status":"ok","timestamp":1638867174673,"user_tz":-60,"elapsed":11,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# # Average number of days elapsed between orders for a given client\n","# train_data.groupby('user_id').days_since_prior_order.mean()"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDC4yJmp6jGO"},"source":["Ideas:\n","\n","- number of reordered products\n","- fraction of reordered products\n","- probability of a product to be reordered\n","- convert date"]},{"cell_type":"markdown","metadata":{"id":"Hez6-Cvd6jGO"},"source":["## Data mining "]},{"cell_type":"markdown","metadata":{"id":"oRmBSP0V6jGP"},"source":["### Multi-label classification based on time of order"]},{"cell_type":"markdown","metadata":{"id":"-nkN7o6tzsVT"},"source":["#### Models and pipelines definition"]},{"cell_type":"markdown","metadata":{"id":"QsA7DiBhzK9T"},"source":["Our goal here is to choose the best classification algorithm for the problem at hand, based on the fitting time and a metric score."]},{"cell_type":"markdown","metadata":{"id":"0U-am7QL6jGP"},"source":["To effectively apply algorithms for a multi-label problem, we either need to transform our carts into a sparse matrix using `sklearn.preprocessing.MultiLabelBinarizer`, or to use `sklearn.multioutput.MultiOutputClassifier` to extend a single variable classifier into a multi-label one."]},{"cell_type":"code","metadata":{"id":"-VFY5tKQHWSx","executionInfo":{"status":"ok","timestamp":1638875934862,"user_tz":-60,"elapsed":269,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["numerical_cols = ['order_dow', 'order_hour_of_day', 'days_since_prior_order']\n","# Impute the average over all orders\n","avg_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n","\n","# Imputing the average for a given client in a pipeline necessitates writing a custom imputer.\n","# This is optional and will be done if there is enough time.\n","\n","# Min-max normalization \n","mm_scaler = MinMaxScaler()\n","std_scaler = StandardScaler()\n","\n","# Define the preprocessor\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', avg_imp, numerical_cols),\n","        ('norm', std_scaler, numerical_cols)\n","    ])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQ7AQPrxIJJz","executionInfo":{"status":"ok","timestamp":1638875934864,"user_tz":-60,"elapsed":12,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# Create the different models\n","\n","# Random Forest Classifier\n","RF_model = RandomForestClassifier(n_estimators=100, verbose=True)\n","multi_RF_model = MultiOutputClassifier(RF_model, n_jobs=-1)\n","\n","# Linear SVC Classifier\n","# Set dual to false as samples>>features\n","LSVC_model = LinearSVC(dual=False, verbose=True)\n","multi_LSVC_model = MultiOutputClassifier(LSVC_model, n_jobs=-1)\n","\n","# SGD Classifier\n","# Use Nystroem transform to get an approximate kernel\n","SGD_model = SGDClassifier(verbose=True)\n","multi_SGD_model = MultiOutputClassifier(SGD_model, n_jobs=-1)\n","\n","# kNN Classifier\n","# Use GridSearchCV to tune k\n","kNN_model = KNeighborsClassifier()\n","multi_kNN_model = MultiOutputClassifier(kNN_model, n_jobs=-1)\n","\n","#MLP Classifier\n","MLP_model = MLPClassifier(verbose=True)\n","multi_MLP_model = MultiOutputClassifier(MLPClassifier(), n_jobs=-1)\n","\n","# lgbm Classifier\n","lgbm_model = lgb.LGBMClassifier()\n","multi_lgbm_model = MultiOutputClassifier(lgbm_model, n_jobs=-1)\n","\n","# xgb Classifier\n","xgb_model = xgb.XGBClassifier()\n","multi_xgb_model = MultiOutputClassifier(xgb_model, n_jobs=-1)\n","\n","# # Default Classifier\n","# model = example_model()\n","# multi_model = MultiOutputClassifier(model, n_jobs=-1)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWwvddb0Y9IZ","executionInfo":{"status":"ok","timestamp":1638876269977,"user_tz":-60,"elapsed":226,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# Make the different pipelines\n","\n","# Random Forest Classifier\n","# Not compatible with sparse matrix output\n","RF_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('RF model', multi_RF_model)\n","                             ],\n","                       verbose=True)\n","\n","# Linear SVC Classifier\n","LSVC_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('LSVC model', multi_LSVC_model)\n","                             ],\n","                        verbose=True)\n","\n","# SGD Classifier\n","SGD_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('SGD model', multi_SGD_model)\n","                             ],\n","                        verbose=True)\n","\n","# kNN Classifier\n","kNN_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('kNN model', multi_kNN_model)\n","                             ],\n","                        verbose=True)\n","\n","# MLP Classifier\n","MLP_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('MLP model', multi_MLP_model)\n","                             ],\n","                        verbose=True)\n","\n","# lgbm Classifier\n","lgbm_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('lgbm model', multi_lgbm_model)\n","                             ],\n","                        verbose=True)\n","\n","# lgbm Classifier\n","xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('xgb model', multi_xgb_model)\n","                             ],\n","                        verbose=True)\n","\n","# # Default Classifier\n","# pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","#                               ('OVR model', OVR_model)\n","#                          ],\n","#                     verbose=True)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"kE0lWFjCZ-Ao","executionInfo":{"status":"ok","timestamp":1638873485527,"user_tz":-60,"elapsed":2301,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# Train and validate the models\n","features = ['order_dow', 'order_hour_of_day', 'days_since_prior_order']\n","target = 'cart'\n","\n","# Reduce dataset size to overcome training memory issues...\n","train_sample = train_data.sample(axis=0, frac=1/50)\n","\n","# Define target and features\n","X = train_sample[features]\n","y = train_sample[target]\n","\n","# Fit the MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()\n","mlb.fit(y)\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n","\n","# Convert the target data into binary matrix\n","y_train_bm = mlb.transform(y_train)\n","y_test_bm = mlb.transform(y_test)"],"execution_count":132,"outputs":[]},{"cell_type":"code","metadata":{"id":"CrAB1wmrOi1R","executionInfo":{"status":"ok","timestamp":1638873487110,"user_tz":-60,"elapsed":867,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["# # Apply Nystroem kernel approximation (unused)\n","# # Used eventually for SGD or LSVC models\n","# feature_map_nystroem = Nystroem(gamma=.2,\n","#                                 random_state=1,\n","#                                 n_components=300)\n","# X_train_nys = feature_map_nystroem.fit_transform(X_train)"],"execution_count":133,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yeNzniIpz145"},"source":["#### Utility functions for fitting and comparing models"]},{"cell_type":"markdown","metadata":{"id":"cjm1UrHvW4sR"},"source":["We define functions for fitting, scoring, and comparing all models at once."]},{"cell_type":"code","metadata":{"id":"aAyyuVFVDCHT","executionInfo":{"status":"ok","timestamp":1638876149345,"user_tz":-60,"elapsed":695,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["def fit_score(model, X_train, X_test, y_train, y_test):\n","  \"\"\"Fits the given multi-label model and scores it\n","  using the four metrics below\"\"\"\n","  # Fit the model\n","  model.fit(X_train, y_train)\n","\n","  # Predict\n","  y_pred = model.predict(X_test)\n","\n","  # Score the model\n","  f1 = f1_score(y_test, y_pred, average='samples')\n","  accuracy = accuracy_score(y_test, y_pred)\n","  hamming = hamming_loss(y_test, y_pred)\n","  jaccard = jaccard_score(y_test, y_pred, average='samples')\n","\n","  return model, y_pred, f1, hamming, accuracy, jaccard\n","  \n","def compare_models(pipelines):\n","  \"\"\"Fit and compare models based on speed and four metrics\"\"\"\n","  models = []\n","  predictions = []\n","  for p in pipelines:\n","    model, y_pred, f1, hamming, accuracy, jaccard = fit_score(p,\n","                                                          X_train,\n","                                                          X_test,\n","                                                          y_train_bm,\n","                                                          y_test_bm)\n","    models.append(model)\n","    predictions.append(y_pred)\n","    print('f1-score:', f1)\n","    print('accuracy score:', accuracy)\n","    print('hamming loss:', hamming)\n","    print('jaccard score:', jaccard)\n","  return models, predictions"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bf2nefB1W-rn"},"source":["We also define functions that make the predictions human readable."]},{"cell_type":"code","metadata":{"id":"-7R5VZdDPKmr","executionInfo":{"status":"ok","timestamp":1638876151461,"user_tz":-60,"elapsed":263,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}}},"source":["def convert_to_carts(y_pred):\n","  \"\"\"Convert back binary matrix prediction outputs to human readable carts\"\"\"\n","  arr = mlb.inverse_transform(y_pred)\n","  carts = [[] for i in range (len(arr))]\n","  for i in range(len(arr)):\n","    for id in arr[i]:\n","      carts[i].append(products.loc[id].product_name)\n","  return carts\n","\n","def print_carts(y_pred):\n","  \"\"\"Print carts and number of empty carts.\n","     y_ pred must be in binary matrix format.\"\"\"\n","  carts = pd.Series(convert_to_carts(y_pred))\n","  empty = 0\n","  for cart in carts:\n","    if cart == []:\n","      empty+=1\n","    else:\n","      print(cart)\n","  print('Number of empty carts:', empty)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yRSJmfFzz8CY"},"source":["#### Model comparison"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvXTmHEUYIhe","executionInfo":{"status":"ok","timestamp":1638874124442,"user_tz":-60,"elapsed":637336,"user":{"displayName":"Remy Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64","userId":"09294683799950681344"}},"outputId":"d4803e4c-a9a9-4b36-e7b5-68cecd8ba4d0"},"source":["# Compare the different models with default parameters\n","pipelines = [RF_pipeline,\n","             LSVC_pipeline,\n","             SGD_pipeline,\n","             kNN_pipeline,\n","             MLP_pipeline,\n","             lgbm_pipeline,\n","             xgb_pipeline]\n","\n","models, preds = compare_models(pipelines)"],"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] .......... (step 2 of 2) Processing RF model, total= 2.6min\n","f1-score: 0.005799319107462107\n","accuracy score: 0.0006037735849056604\n","hamming loss: 0.03302297776947506\n","jaccard score: 0.003997075103956346\n","[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] ........ (step 2 of 2) Processing LSVC model, total=   4.2s\n","f1-score: 0.0\n","accuracy score: 0.0\n","hamming loss: 0.03156062021296469\n","jaccard score: 0.0\n","[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] ......... (step 2 of 2) Processing SGD model, total=  21.9s\n","f1-score: 0.0\n","accuracy score: 0.0\n","hamming loss: 0.03156062021296469\n","jaccard score: 0.0\n","[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   4.7s\n","f1-score: 0.010316129634331633\n","accuracy score: 0.002339622641509434\n","hamming loss: 0.032739024845880815\n","jaccard score: 0.007594356272658158\n","[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] ......... (step 2 of 2) Processing MLP model, total= 4.1min\n","f1-score: 0.0\n","accuracy score: 0.0\n","hamming loss: 0.03156062021296469\n","jaccard score: 0.0\n","[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] ........ (step 2 of 2) Processing lgbm model, total=  24.9s\n","f1-score: 0.0\n","accuracy score: 0.0\n","hamming loss: 0.031574817859144406\n","jaccard score: 0.0\n","[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n","[Pipeline] ......... (step 2 of 2) Processing xgb model, total= 1.5min\n","f1-score: 0.0\n","accuracy score: 0.0\n","hamming loss: 0.03156062021296469\n","jaccard score: 0.0\n"]}]},{"cell_type":"code","metadata":{"id":"30mNgXaQYcmd"},"source":["# Fit LSVC and SGD using Nystroem transform (unused)\n","# m2, y_pred2, f12, hamming2, accuracy2, jaccard2 = fit_score(LSVC_pipeline,X_train_nys,X_test,y_train_bm,y_test_bm)\n","# m1, y_pred1, f11, hamming1, accuracy1, jaccard1 = fit_score(SGD_pipeline,X_train_nys,X_test,y_train_bm,y_test_bm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCLKLBI10Bl0"},"source":["#### Conclusions"]},{"cell_type":"markdown","metadata":{"id":"T6y7JMOnZEd-"},"source":["Here we choose to use the Jaccard score to compare our models.\n","\n","Conclusions:\n","- The Random Forest Classifier takes a long time to train but appears to work correctly.\n","- The Linear Support Vector Classification method does not work and only predicts empty carts.\n","- The Stochastic Gradient Descend method does not work and only predicts empty carts.\n","- k-NearestNeighbors is much quicker than using Random Forest, and results in better performances with less empty carts.\n","- The MultiLayerPercetron method does not work and only predicts empty carts.\n","- The lightGradientBoosted method returns only a handful of carts with only one or two product each.\n","- The ExtremeGradientBoosting method does not work and only predicts empty carts.\n","\n","Therefore the k-NearestNeighbors method is priviledged for this situation."]},{"cell_type":"markdown","metadata":{"id":"lskgvD5tjrk-"},"source":["The cell below prints carts according to the predicted results."]},{"cell_type":"code","metadata":{"id":"TTaggy9zXQPW"},"source":["# Chose i to print carts depending on model\n","# 0 RF_pipeline\n","# 1 LSVC_pipeline\n","# 2 SGD_pipeline\n","# 3 kNN_pipeline\n","# 4 MLP_pipeline\n","# 5 lgbm_pipeline\n","# 6 xgb_pipeline\n","\n","i=3\n","print_carts(preds[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVPr6y6_kHAo"},"source":["We can now optimize our selected model.\n","\n","See `SD201-Instacart-MultiLabel-kNN.ipynb` for the next step."]}]}