{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNu4gWEe6jFc"
   },
   "source": [
    "# SD201 Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H58LEM-p6jFi"
   },
   "source": [
    "## Dataset (from a Kaggle competition) : Instacart Market Basket Analysis\n",
    "\n",
    "Link : https://www.kaggle.com/c/instacart-market-basket-analysis/data\n",
    "\n",
    "Blog post about the competition : https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2\n",
    "\n",
    "Key points from the dataset:\n",
    "\n",
    "- 3M grocery store orders\n",
    "- 200,000+ Instacart users\n",
    "- 4 to 100 orders for each user, timestamped\n",
    "\n",
    "“The Instacart Online Grocery Shopping Dataset 2017”, Accessed from https://www.instacart.com/datasets/grocery-shopping-2017 on 10/12/2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8dXK7_G6jFl"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8-Mt_p56jFn"
   },
   "source": [
    "In this notebook, we seek to optimise the k-NearestNeighbors classifier that we have chosen previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aroataTar3Kw"
   },
   "source": [
    "### Setup (run all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15703,
     "status": "ok",
     "timestamp": 1638958729835,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "d39Vhguc6umn",
    "outputId": "72530050-2807-4a11-98af-06e23250484e"
   },
   "outputs": [],
   "source": [
    "# # Run cell if using Google Colab\n",
    "# # Mount the private Google Drive folder to access the .csv files\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1638958734020,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "xuEqPgz46jFt"
   },
   "outputs": [],
   "source": [
    "'''Python librairies''' \n",
    "\n",
    "# Utility librairies\n",
    "import pandas as pd\n",
    "import scipy.stats as s\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing and pipeline librairies\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Wrapper to convert regular classifiers to multi-label classifiers\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Classifiers that support multi-label output\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# To optimize hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Plotting (unused)\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 25100,
     "status": "ok",
     "timestamp": 1638958759117,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "V4eTpcxL6jFw"
   },
   "outputs": [],
   "source": [
    "# Open the data\n",
    "path_to_csv = './instacart/'\n",
    "\n",
    "op_prior = pd.read_csv(path_to_csv + 'order_products__prior.csv')\n",
    "op_train = pd.read_csv(path_to_csv + 'order_products__train.csv')\n",
    "orders   = pd.read_csv(path_to_csv + 'orders.csv')\n",
    "products = pd.read_csv(path_to_csv + 'products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un2cnv2u6jGG"
   },
   "source": [
    "## Data cleaning (run all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etqNM9Ih890u"
   },
   "source": [
    "We cannot exploit our relational data directly: we need to perform merges using the keys in the data, and then perform an aggregation over the ordered products to get arrays of ordered products for each order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujUGWInbccn5"
   },
   "source": [
    "Moreover, instead of keeping all the items (which poses memory problems when applying the mining algorithms), we can keep only the most frequent items according to what was done in EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z34b-c6P9A9v"
   },
   "source": [
    "As we will see, this poses some limitations but gives preliminary insights for the Instacart platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1638958759120,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "uvnGnlqIcbUu"
   },
   "outputs": [],
   "source": [
    "# Set product_id as index to avoid problems when using loc\n",
    "products.set_index('product_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1638958759459,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "W0udu5p3SHDs"
   },
   "outputs": [],
   "source": [
    "threshold = 5e-4\n",
    "order_count = len(op_prior)\n",
    "\n",
    "# Create the DataFrame of ordered products with their frequencies\n",
    "item_freq = op_prior.product_id.value_counts(ascending=False)\n",
    "item_freq = pd.DataFrame(item_freq.reset_index())\n",
    "item_freq.rename(columns={'product_id':'n_occ', 'index':'product_id'}, inplace= True)\n",
    "item_freq['frequency'] = item_freq['n_occ']/order_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1638958759461,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "UsrWrRQPbDjm",
    "outputId": "8e5dc9e0-07d9-44cd-cad1-6e8361b765fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products before : 49677 after: 250\n"
     ]
    }
   ],
   "source": [
    "# Compare the number of products before and after the drop\n",
    "bf_size = len(item_freq)\n",
    "item_freq = item_freq[item_freq.frequency>threshold]\n",
    "af_size = len(item_freq)\n",
    "print('Number of products before :', bf_size, 'after:', af_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7498,
     "status": "ok",
     "timestamp": 1638958766954,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "-K6px5nuSKer"
   },
   "outputs": [],
   "source": [
    "# # Keep first item in cart\n",
    "# first_item_prior = op_prior[op_prior.add_to_cart_order == 1]\n",
    "\n",
    "# Drop all rows with unfrequently bought products\n",
    "op_prior = op_prior[op_prior.product_id.isin(item_freq.product_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1638958766959,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "fQ17OsUM6jGL"
   },
   "outputs": [],
   "source": [
    "def arrange_data(op_data):\n",
    "    '''\n",
    "    Format the data so that to each order corresponds an array of product_id (the cart),\n",
    "    and an array indicating whether an item was reordered or not.\n",
    "    op_data can be either op_train or op_prior.\n",
    "    '''\n",
    "    data = orders.merge(op_data[['order_id', 'product_id']], on='order_id')\n",
    "    \n",
    "    # Aggregate the carts into arrays\n",
    "    groupby_cols = ['order_id',\n",
    "                    'user_id',\n",
    "                    'eval_set',\n",
    "                    'order_number',\n",
    "                    'order_dow',\n",
    "                    'order_hour_of_day',\n",
    "                    'days_since_prior_order']\n",
    "    \n",
    "    data = data.groupby(groupby_cols).aggregate(list)\n",
    "    \n",
    "    # Rename the product_id column to 'cart'\n",
    "    data.rename(columns = {'product_id':'cart'}, inplace = True)\n",
    "    \n",
    "    # Reset the index that was changed by the aggregation\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 70054,
     "status": "ok",
     "timestamp": 1638958837003,
     "user": {
      "displayName": "Remy Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZKt_il_YhovsZglQRqyZLxFMXZYsgVpW3MksDevY=s64",
      "userId": "09294683799950681344"
     },
     "user_tz": -60
    },
    "id": "2KfnmOKD6jGL"
   },
   "outputs": [],
   "source": [
    "# Create the DataFrame with aggregated carts for each order\n",
    "train_data = arrange_data(op_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0L1lYwdFBJ77"
   },
   "outputs": [],
   "source": [
    "# Free the RAM for Google Colab\n",
    "op_prior = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hez6-Cvd6jGO"
   },
   "source": [
    "## Data mining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRmBSP0V6jGP"
   },
   "source": [
    "### Defining the model (run all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv6LsDPs9652"
   },
   "source": [
    "#### Models and pipelines definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U-am7QL6jGP"
   },
   "source": [
    "Same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-VFY5tKQHWSx"
   },
   "outputs": [],
   "source": [
    "numerical_cols = ['order_dow', 'order_hour_of_day', 'days_since_prior_order']\n",
    "# Impute the average over all orders\n",
    "avg_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Imputing the average for a given client in a pipeline necessitates writing a custom imputer.\n",
    "# This is optional and will be done if there is enough time.\n",
    "\n",
    "# Min-max normalization \n",
    "mm_scaler = MinMaxScaler()\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', avg_imp, numerical_cols),\n",
    "        ('norm', std_scaler, numerical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IQ7AQPrxIJJz"
   },
   "outputs": [],
   "source": [
    "# kNN Classifier\n",
    "# Use GridSearchCV to tune k\n",
    "kNN_model = KNeighborsClassifier()\n",
    "multi_kNN_model = MultiOutputClassifier(kNN_model, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nWwvddb0Y9IZ"
   },
   "outputs": [],
   "source": [
    "# kNN Classifier\n",
    "kNN_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('kNN model', multi_kNN_model)\n",
    "                             ],\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjm1UrHvW4sR"
   },
   "source": [
    "We define functions for fitting, scoring, and comparing all models at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aAyyuVFVDCHT"
   },
   "outputs": [],
   "source": [
    "def fit_score(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fits the given multi-label model and scores it\n",
    "    using the four metrics below\"\"\"\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Score the model\n",
    "    f1 = f1_score(y_test, y_pred, average='samples')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    hamming = hamming_loss(y_test, y_pred)\n",
    "    jaccard = jaccard_score(y_test, y_pred, average='samples')\n",
    "\n",
    "    return model, y_pred, f1, hamming, accuracy, jaccard\n",
    "  \n",
    "def compare_models(pipelines):\n",
    "    \"\"\"Fit and compare models based on speed and four metrics\"\"\"\n",
    "    models = []\n",
    "    predictions = []\n",
    "    for p in pipelines:\n",
    "        model, y_pred, f1, hamming, accuracy, jaccard = fit_score(p,\n",
    "                                                              X_train,\n",
    "                                                              X_test,\n",
    "                                                              y_train_bm,\n",
    "                                                              y_test_bm)\n",
    "        models.append(model)\n",
    "        predictions.append(y_pred)\n",
    "        print('f1-score:', f1)\n",
    "        print('accuracy score:', accuracy)\n",
    "        print('hamming loss:', hamming)\n",
    "        print('jaccard score:', jaccard)\n",
    "    return models, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZtAMJzn93E0"
   },
   "source": [
    "#### Utility functions for fitting and comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf2nefB1W-rn"
   },
   "source": [
    "We also define functions that make the predictions human readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-7R5VZdDPKmr"
   },
   "outputs": [],
   "source": [
    "def convert_to_carts(y_pred):\n",
    "    \"\"\"Convert back binary matrix prediction outputs to human readable carts\"\"\"\n",
    "    arr = mlb.inverse_transform(y_pred)\n",
    "    carts = [[] for i in range (len(arr))]\n",
    "    for i in range(len(arr)):\n",
    "        for id in arr[i]:\n",
    "            carts[i].append(products.loc[id].product_name)\n",
    "    return carts\n",
    "\n",
    "def print_carts(y_pred):\n",
    "    \"\"\"Print carts and number of empty carts.\n",
    "     y_ pred must be in binary matrix format.\"\"\"\n",
    "    carts = pd.Series(convert_to_carts(y_pred))\n",
    "    empty = 0\n",
    "    for cart in carts:\n",
    "        if cart == []:\n",
    "            empty+=1\n",
    "        else:\n",
    "            print(cart)\n",
    "    print('Number of empty carts:', empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWUYq41dq7wO"
   },
   "source": [
    "### Model optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVPr6y6_kHAo"
   },
   "source": [
    "We can now optimize our selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVzv5KiKloG0"
   },
   "source": [
    "We start by redefining the dataset by taking more data for the training step, and using the sparse format for our binary matrixes since the kNN model supports it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CM7Y3iCplQic"
   },
   "outputs": [],
   "source": [
    "# Fraction of data to keep\n",
    "frac = 1/30\n",
    "\n",
    "# Train and validate the models\n",
    "\n",
    "features = ['order_dow', 'order_hour_of_day', 'days_since_prior_order']\n",
    "target = 'cart'\n",
    "\n",
    "# Take more data for training\n",
    "train_sample = train_data.sample(axis=0, frac=frac)\n",
    "\n",
    "# Define target and features\n",
    "X = train_sample[features]\n",
    "y = train_sample[target]\n",
    "\n",
    "# Fit the MultiLabelBinarizer with sparse output\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# Convert the target data into binary matrix\n",
    "y_train_bm = mlb.transform(y_train)\n",
    "y_test_bm = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ktvj4WyVvrc7",
    "outputId": "71ba2945-b7c7-42c2-937c-f8b425434b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=  10.6s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   8.9s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   8.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0048834 , 0.00388358, 0.00418727])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do n fold cross-validation\n",
    "n=3\n",
    "scores = cross_val_score(kNN_pipeline, X_train, y_train_bm, cv=n,\n",
    "                         scoring='jaccard_samples', error_score='raise')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM9MxYji0Tib"
   },
   "source": [
    "The scores for all folds are very similar, so we do not need to use cross-validation for our model. There is enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ihOrdOqGvn8W",
    "outputId": "c63296fc-d953-4d7c-8383-4d7e58fe82a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=  13.9s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=  10.8s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.4s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.5s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.6s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.1s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.8s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.2s\n",
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 12.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing kNN model, total=  17.7s\n",
      "{'kNN model__estimator__n_neighbors': 3} 0.009784911053101522\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearch to optimize for k with n folds cross-validation\n",
    "\n",
    "n=3\n",
    "param_grid = {\n",
    "    'kNN model__estimator__n_neighbors':[3,5,10]\n",
    "}\n",
    "score = 'jaccard_samples'\n",
    "\n",
    "clf = GridSearchCV(kNN_pipeline, param_grid=param_grid, scoring=score, cv=n,\n",
    "                   verbose=1)\n",
    "clf.fit(X_train, y_train_bm)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5W0t_qAbawPk"
   },
   "outputs": [],
   "source": [
    "# To get keys use the commented code below\n",
    "# kNN_pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVK2nXfg6UkT"
   },
   "source": [
    "Our best parameter is k=3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `SD201_Instacart_AssociationRuleMining.ipynb` for the next step."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SD201-Instacart-MultiLabel-kNN.ipynb",
   "provenance": [
    {
     "file_id": "1bodbcSmWrU9e1CrElMpy-8BteCx95Ylk",
     "timestamp": 1638876531868
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
