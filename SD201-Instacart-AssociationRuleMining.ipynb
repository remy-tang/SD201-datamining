{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD201 Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (from a Kaggle competition) : Instacart Market Basket Analysis\n",
    "\n",
    "Link : https://www.kaggle.com/c/instacart-market-basket-analysis/data\n",
    "\n",
    "Blog post about the competition : https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2\n",
    "\n",
    "Key points from the dataset:\n",
    "\n",
    "- 3M grocery store orders\n",
    "- 200,000+ Instacart users\n",
    "- 4 to 100 orders for each user, timestamped\n",
    "\n",
    "“The Instacart Online Grocery Shopping Dataset 2017”, Accessed from https://www.instacart.com/datasets/grocery-shopping-2017 on 10/12/2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we seek to use association rule mining algorithm to make recommendations based on frequently bought-together items from the Instacart online store platform.\n",
    "\n",
    "We will use and compare the following algorithms :\n",
    "\n",
    "- Apriori algorithm\n",
    "- Frequent Pattern Growth Algorithm (FP-Growth)\n",
    "- ECLAT algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Python librairies''' \n",
    "\n",
    "# Utility librairies\n",
    "import pandas as pd\n",
    "import scipy.stats as s\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Association rule preprocessing librairies\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Association rule mining librairies\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.frequent_patterns.fpgrowth import fpgrowth\n",
    "from pyECLAT import ECLAT\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Pretty charts\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data\n",
    "op_prior = pd.read_csv('./instacart/order_products__prior.csv')\n",
    "orders = pd.read_csv('./instacart/orders.csv')\n",
    "products = pd.read_csv('./instacart/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For association rule mining we only need `order_id` and the ordered products for each order. Since there are not any null entries in the carts data, we do not have to deal with `nan` values here.\n",
    "\n",
    "However there are some null entries in the `days_since_prior_order` that we have to deal with for multi-label classification (see `SD201-Instacart-MultiLabelClassification` notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot exploit our relational data directly: we need to perform merges using the keys in the data, and then perform an aggregation over the ordered products to get arrays of ordered products for each order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, instead of keeping all the items (which poses memory problems when applying the mining algorithms), we can keep only the most frequent items according to what was done in EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products before : 49677 after: 1756\n"
     ]
    }
   ],
   "source": [
    "threshold = 10e-5\n",
    "order_count = len(op_prior)\n",
    "\n",
    "# Create the DataFrame of ordered products with their frequencies\n",
    "item_freq = op_prior.product_id.value_counts()\n",
    "item_freq = pd.DataFrame(item_freq.reset_index())\n",
    "item_freq.rename(columns={'product_id':'n_occ', 'index':'product_id'}, inplace= True)\n",
    "item_freq['frequency'] = item_freq['n_occ']/order_count\n",
    "item_freq = item_freq.merge(products[['product_id', 'product_name']], on='product_id')\n",
    "\n",
    "# Compare the number of products before and after the drop\n",
    "bf_size = len(item_freq)\n",
    "item_freq = item_freq[item_freq.frequency>threshold]\n",
    "af_size = len(item_freq)\n",
    "print('Number of products before :', bf_size, 'after:', af_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with unfrequently bought products\n",
    "op_prior = op_prior[op_prior.product_id.isin(item_freq.product_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_data(op_data):\n",
    "    '''\n",
    "    Format the data so that to each order corresponds an array of products (the carts).\n",
    "    op_data can be either op_train or op_prior.\n",
    "    '''\n",
    "    \n",
    "    # Merge product information with order information\n",
    "    data = op_data[['order_id', 'product_id']]\n",
    "    data = data.merge(products[['product_id', 'product_name']], on='product_id')\n",
    "    \n",
    "    # Aggregate the carts into arrays\n",
    "    groupby_cols = ['order_id']\n",
    "    data = data.groupby(groupby_cols).aggregate(lambda x: list(x))\n",
    "    \n",
    "    # Rename the product_id column to 'cart'\n",
    "    data.rename(columns = {'product_id':'cart'}, inplace = True)\n",
    "    data.rename(columns = {'product_name':'cart_names'}, inplace = True)\n",
    "    \n",
    "    # Reset the index that was changed by the aggregation\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame with aggregated carts for each order\n",
    "data = arrange_data(op_prior)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association rule mining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions and metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apriori algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Apriori algorithm is highly inefficient for large datasets (complexity in ...), we use the Apriori property to reduce the size of the set of products on which we apply the Apriori algorithm.\n",
    "\n",
    "The Apriori property states that :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FP-Growth algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the transactions by one-hot-encoding them\n",
    "te = TransactionEncoder()\n",
    "te.fit(list(data.cart))\n",
    "ohe_transactions = te.transform(list(data.cart))\n",
    "ohe_transactions_df = pd.DataFrame(ohe_transactions, columns=te.columns_)\n",
    "print(ohe_transactions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
